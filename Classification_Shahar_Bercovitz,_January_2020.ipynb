{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification - Shahar Bercovitz, January 2020.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "ijeRwS-Duzq6",
        "fm1QlyQD8agR",
        "miQ0nJJ65dQw",
        "OLcZdmyu5tF3",
        "1BiEoPQV63XJ",
        "o7GfiEUc-rYJ",
        "Ebn0CUPdEAiu",
        "1p9ph6ha7IGR",
        "BZhDjnLKY3wG",
        "TcgqJ2Og8AA-",
        "kP4fulSu8Awb",
        "18YXhC5r8COB",
        "7vNK0Qtf8Cye",
        "vzgtn8lOHsjV",
        "gw4g9g1CW-vF",
        "YLjoMO20qkdI",
        "057UpI1_qr36",
        "g9SUXnyWi1ej",
        "1GQulETVcWD_",
        "PIuhD1BMdIxS",
        "yPPfeBN6ir4o",
        "924U_x9jU7VI",
        "CIPqJoVTVLXu",
        "GSggUSAMl3ud",
        "o8hhv1_ZXxqn",
        "o77PrW5XYWnI",
        "HICeTvQodte0",
        "2SXiCT2GYunE",
        "Y00YLM-oRveY",
        "IKNBKF9EcuFr",
        "L8t1PQsduVob",
        "inBnoBUGxCUs",
        "st0ewZG1yo0P",
        "ybVTQevaxaLS",
        "w6Z_Iw8uc7Bq",
        "9k9UABn7dFpC",
        "kUdB9F91w8ah",
        "EL76PjMYjlQt",
        "hGuWhLtwsTH3",
        "GidWYE8lY56u",
        "Uw3sR2cuweZv",
        "7yH9ko6HskR3",
        "fCaT-D_sxYjR",
        "T9jL64wKrvsE",
        "0t8oUU3PwY7s",
        "rm2vLIUNzrvR",
        "ddUi3pan0c4c",
        "VsrHkhk_GU0t",
        "_eCHltDoxOl8",
        "wgzP6aHJx0gr",
        "Ft92xARjHets",
        "7N5sutzyHrgb",
        "4NdWAbh2ITA5",
        "b21tYnP3AU-8",
        "OtdtEiAtxpyM",
        "ARqHXJ9uxpyO",
        "X1hYJmNExpyp",
        "Inwzy6Yhxpyw",
        "iDLKXtmDCyMP",
        "MXZoGO9_CyMR",
        "WMsIYv5jf6_H",
        "HsYyoUZ3CyMk",
        "gtt9eyCFCyMq",
        "58zoG3DRCyMs",
        "Pns2jhV8CyM1",
        "5GASLWD9CyM4",
        "ptSz_z6Tqoi6",
        "BiAs6Kuzv2zc",
        "5xlh2MYTv-UH",
        "uMjjwHuXQngV",
        "la7M7W5CQ1t1",
        "KNznbeurvxHO",
        "SL2zQlT3ILqh",
        "M-eOkZLIxFTe",
        "VUV5kU-_xdt-",
        "uc8360OfwAeD",
        "6N6lSRcUV75H",
        "KIXBjMMDHyAf",
        "ZMQQNqQvTt4Y",
        "Jg8SywGTwH0S",
        "wUj0mxeQjqX5",
        "yi6dcQa2wNX8",
        "iAZbJRRkl2zO",
        "zEZ0G-YCAA6I"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shahar19/Python/blob/master/Classification_Shahar_Bercovitz%2C_January_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijeRwS-Duzq6"
      },
      "source": [
        "## **Classification project - Titanic - Shahar B, January 2020**\n",
        "*Binary classification*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm1QlyQD8agR"
      },
      "source": [
        "# **Import Packages**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMywStj7v2Vp"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "# Preprocess tools\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Models\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import log_loss, accuracy_score, confusion_matrix, classification_report, auc\n",
        "\n",
        "# Visualizations\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "import pickle\n",
        "from sys import modules\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miQ0nJJ65dQw"
      },
      "source": [
        "# **Data Description**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nkCKS0h8wZm"
      },
      "source": [
        " **Data Overview**\n",
        "\n",
        "Source: Kaggle\n",
        "\n",
        "dataset link: https://www.kaggle.com/c/titanic\n",
        "\n",
        "\n",
        "Data Description\n",
        "Overview\n",
        "The data has been split into two groups:\n",
        "\n",
        "training set (train.csv)\n",
        "test set (test.csv)\n",
        "\n",
        "The training set should be used to build your machine learning models. For the training set, we provide the outcome (also known as the “ground truth”) for each passenger. Your model will be based on “features” like passengers’ gender and class. You can also use feature engineering to create new features.\n",
        "\n",
        "The test set should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.\n",
        "\n",
        "We also include gender_submission.csv, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.\n",
        "\n",
        "\n",
        "*Variable Notes*\n",
        "pclass: A proxy for socio-economic status (SES)\n",
        "1st = Upper\n",
        "2nd = Middle\n",
        "3rd = Lower\n",
        "\n",
        "age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
        "\n",
        "sibsp: The dataset defines family relations in this way...\n",
        "Sibling = brother, sister, stepbrother, stepsister\n",
        "Spouse = husband, wife (mistresses and fiancés were ignored)\n",
        "\n",
        "parch: The dataset defines family relations in this way...\n",
        "Parent = mother, father\n",
        "Child = daughter, son, stepdaughter, stepson\n",
        "Some children travelled only with a nanny, therefore parch=0 for them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLcZdmyu5tF3"
      },
      "source": [
        "# **Get the dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BiEoPQV63XJ"
      },
      "source": [
        "## **Upload data files**\n",
        "1. **Upload dataset CSV format file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ybqg7rl7w1ZS"
      },
      "source": [
        "# def user_upload_multiple_files():\n",
        "#     number_of_files = int(input(\"please enter number of files to upload\\n\"))\n",
        "\n",
        "#     for file in range(0,number_of_files):\n",
        "#         if 'google.colab' in modules:\n",
        "#             from google.colab import files\n",
        "#             uploaded = files.upload()\n",
        "# user_upload_multiple_files()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7GfiEUc-rYJ"
      },
      "source": [
        "# **Data Manipulation and EDA - Research**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ebn0CUPdEAiu"
      },
      "source": [
        "## **Data Madipulation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1p9ph6ha7IGR"
      },
      "source": [
        "### **Read Data file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulA3VJGY7PxP"
      },
      "source": [
        "df = pd.read_csv(r'train.csv', encoding=\"UTF-8\", index_col=\"PassengerId\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZhDjnLKY3wG"
      },
      "source": [
        "### **Target Varibale Definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fo3ttW84Y483"
      },
      "source": [
        "target_variable = \"Survived\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcgqJ2Og8AA-"
      },
      "source": [
        "### **Data Head**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "booX59Jx7-zN"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kP4fulSu8Awb"
      },
      "source": [
        "### **Data Tail**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZHMWRMH8BQl"
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18YXhC5r8COB"
      },
      "source": [
        "### **Dataset info**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WViQ334q8CiN"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vNK0Qtf8Cye"
      },
      "source": [
        "### **Describe dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3CS7Lus8DCr"
      },
      "source": [
        "df.describe().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzgtn8lOHsjV"
      },
      "source": [
        "### **Target variable proportion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0VKvdlvHqrC"
      },
      "source": [
        "df[target_variable].value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw4g9g1CW-vF"
      },
      "source": [
        "### **Pairplot**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2de0KntITWi"
      },
      "source": [
        "sns.pairplot(df, hue=target_variable, plot_kws={'alpha': 0.5})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVZvUTGzavL5"
      },
      "source": [
        "**Pair Plot Notes**\n",
        "\n",
        "**Age**\n",
        "\n",
        "We can see that Titanic passenger's age has normalize distibution from 5 months old baby to age of 80 years old.\n",
        "mean and median age is 28-30.\n",
        "\n",
        "There are more survivers than losts among the young ages.\n",
        "\n",
        "\n",
        "**P class**\n",
        "\n",
        "The vast majority of Passangers were in the low class (3rd).\n",
        "we can see that there are many losses in that class.\n",
        "In opose to the upper class (1st) where most of the passangers among this class survived. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLjoMO20qkdI"
      },
      "source": [
        "### **Check Nulls**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKNVpseftci4"
      },
      "source": [
        "df.isnull().sum(axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojav8mNBnDSu"
      },
      "source": [
        "**Pre-processing insights:**\n",
        "\n",
        "There is nulls values in age, Cabin and 2 in the Embarked data points.\n",
        "\n",
        "1. Age - We will consider filling the age nulls values using person title feature.\n",
        "we'll extract a person's title from his name (Mr., Mrs, etc).\n",
        "The hypothesis is that a person's title can indicate his approximate age.\n",
        "\n",
        "2. Cabin - there are A LOT of nulls in this data point.\n",
        "We'll try to use it anyway, using the 1st letter of the cabin as a feature, and we'll fill the nulls with \"Not Mentioned\" as it's own category.\n",
        "\n",
        "3. Embarked - we'll fill the two nulls with the most-frequent Embarked port."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "057UpI1_qr36"
      },
      "source": [
        "### **Handle Nulls**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9SUXnyWi1ej"
      },
      "source": [
        "#### Handle Nulls and 0s in age"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GQulETVcWD_"
      },
      "source": [
        "##### Create Title Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncf5ZoWEqw6Y"
      },
      "source": [
        "regex_pattern_name = ('([a-zA-z]*)\\.(.*)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFhOd4YzlKTZ"
      },
      "source": [
        "def extract_title_from_name(string):\n",
        "    title = re.search(regex_pattern_name, string)\n",
        "    if not title:\n",
        "        return 'No Title'\n",
        "    return title.group(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3cWWPf1aX7W"
      },
      "source": [
        "df['Passanger Title'] = df['Name'].apply(extract_title_from_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq5tGA_Ta3xU"
      },
      "source": [
        "df['Passanger Title'].value_counts(normalize=False) #True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92kN5ymhm5it"
      },
      "source": [
        "title_dict = {  \n",
        "                \"Mr\" : \"Mr\",\n",
        "                \"Miss\" : \"Miss\",\n",
        "                \"Mrs\" : \"Mrs\",\n",
        "                \"Master\" : \"Master\",\n",
        "                \"Dr\" : \"Mr\",\n",
        "                \"Rev\" : \"Other\",\n",
        "                \"Col\" : \"Other\",\n",
        "                \"Major\" : \"Mr\",\n",
        "                \"Mlle\" : \"Miss\",\n",
        "                \"Jonkheer\" : \"Other\",\n",
        "                \"Lady\" : \"Mrs\",\n",
        "                \"Capt\" : \"Mr\",\n",
        "                \"Sir\" : \"Mr\",\n",
        "                \"Mme\" : \"Miss\",\n",
        "                \"Countess\" : \"Mrs\",\n",
        "                \"Ms\" : \"Miss\",\n",
        "                \"Don\" : \"Mr\"\n",
        "                }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kdc_zNr3ST_4"
      },
      "source": [
        "df['Passanger Title'] = np.where(df['Passanger Title'].isin(title_dict), df['Passanger Title'].map(title_dict), \"Other\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5z64e51eMYL"
      },
      "source": [
        "df[df['Passanger Title']=='Master'].sort_values('Age',ascending = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgFgv7D9TdjA"
      },
      "source": [
        "**Insights**\n",
        "\n",
        "\"Master\" name title is for childrens ('Age under 12')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIuhD1BMdIxS"
      },
      "source": [
        "##### Group by and filling Age nulls"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7hYpQajdlTh"
      },
      "source": [
        "df.groupby(['Passanger Title'])['Age'].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9TAhK6ZeBIj"
      },
      "source": [
        "age_dict = df.groupby(['Passanger Title'])['Age'].mean().to_dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K29UNlMJhBpu"
      },
      "source": [
        "df.loc[(df['Age'].isnull()) | (df['Age']==0),'Age'] = df['Passanger Title'].map(age_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLzVXkG_gVcY"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPPfeBN6ir4o"
      },
      "source": [
        "#### Handle Nulls and 0s in Embarked"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "924U_x9jU7VI"
      },
      "source": [
        "##### calculate port with max passengers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLjO_9BVUhMt"
      },
      "source": [
        "max_embarked_port = df['Embarked'].value_counts().idxmax()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIPqJoVTVLXu"
      },
      "source": [
        "##### fill nulls with port with max passengers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgMdAwk6htOu"
      },
      "source": [
        "df.loc[df['Embarked'].isnull(), 'Embarked'] = str(max_embarked_port)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrFdd-VCXBil"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSggUSAMl3ud"
      },
      "source": [
        "####Handle with 0's in Cabin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKwLbBm0i3W1"
      },
      "source": [
        "regex_pattern_cabin = ('^([A-Z])(\\d*)$')\n",
        "\n",
        "def extract_cabin_class_from_cabin(string):   \n",
        "    if string == 'Not Mentioned':\n",
        "        return 'Not Mentioned'\n",
        "    cabin_class = re.search(regex_pattern_cabin, string)\n",
        "    if not cabin_class:\n",
        "        return 'Not Mentioned'\n",
        "    return cabin_class.group(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVV3Xh0ulNjx"
      },
      "source": [
        "df['Cabin'].fillna('Not Mentioned', inplace=True)\n",
        "df['Cabin Class'] = df['Cabin'].apply(extract_cabin_class_from_cabin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bu69V1CEoQ0p"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gP6b4R-XpAJ"
      },
      "source": [
        "**No more nulls**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8hhv1_ZXxqn"
      },
      "source": [
        "### **Feature Extraction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o77PrW5XYWnI"
      },
      "source": [
        "#### Fare Per Ticket"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xco6ijXmqcEx"
      },
      "source": [
        "num_member_dict = df.groupby(['Ticket'])['Name'].count().to_dict()\n",
        "df.loc[:,'num_of_members'] = df['Ticket'].map(num_member_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSCk2DBgmAkL"
      },
      "source": [
        "df['fare_per_ticket'] = df['Fare'] / df['num_of_members']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94gfQu9znPA9"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HICeTvQodte0"
      },
      "source": [
        "#### Fare Buckets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3qgBiNUd0gy"
      },
      "source": [
        "df['fare_per_ticket'].hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9ejeKtDeoAd"
      },
      "source": [
        "fare_buckets=pd.qcut(df['fare_per_ticket'],4).unique().to_list()\n",
        "fare_buckets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQz_XYwidxLU"
      },
      "source": [
        "fare_buckets_dict = {\n",
        "                    (0, 7.762) : 0,\n",
        "                    (7.762, 8.85) : 1,\n",
        "                    (8.85, 24.288) : 2,\n",
        "                    (24.288, math.inf) : 3\n",
        "                    }   \n",
        "for bounds, value in fare_buckets_dict.items():\n",
        "    lower_bound, upper_bound = bounds\n",
        "    df.loc[((df['fare_per_ticket'] > lower_bound) & (df['fare_per_ticket'] <= upper_bound)), \"fare_buckets\"] = value\n",
        "df.loc[df['fare_buckets'].isnull(), \"fare_buckets\"] = -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDkMJraBhKYQ"
      },
      "source": [
        "df.fare_buckets.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVfcYbyCQTZv"
      },
      "source": [
        "df.num_of_members.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SXiCT2GYunE"
      },
      "source": [
        "#### Age Buckets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1jEDhP4Y4D_"
      },
      "source": [
        "df.Age.hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paQsRnlraXOS"
      },
      "source": [
        "age_buckets_dict = {\n",
        "                    (0, 18) : 0,\n",
        "                    (18, 29) : 1,\n",
        "                    (29, 40) : 2,\n",
        "                    (40, 55) : 3,\n",
        "                    (55,  math.inf): 4\n",
        "                    }   \n",
        "for bounds, value in age_buckets_dict.items():\n",
        "    lower_bound, upper_bound = bounds\n",
        "    df.loc[((df.Age > lower_bound) & (df.Age <= upper_bound)), \"age_buckets\"] = value\n",
        "df.loc[df.age_buckets.isnull(), \"age_buckets\"] = -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsbQ9HVKcu_3"
      },
      "source": [
        "df.age_buckets.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y00YLM-oRveY"
      },
      "source": [
        "#### Gender"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ3ltVmeRyhT"
      },
      "source": [
        "df['is_male?'] = np.where((df['Sex']=='male'), 1, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKNBKF9EcuFr"
      },
      "source": [
        "#### number of family members onboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QAk2t7QdFCM"
      },
      "source": [
        "df.loc[:, 'family_onboard'] = df.Parch + df.SibSp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_HcwksLdhja"
      },
      "source": [
        "df.family_onboard.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YirDK_KneC8h"
      },
      "source": [
        "family_onboard_dict = {\n",
        "                    (0, 0) : 0,\n",
        "                    (1, 1) : 1,\n",
        "                    (2, 2) : 2,\n",
        "                    (3,  math.inf) : 3\n",
        "                    }   \n",
        "for bounds, value in family_onboard_dict.items():\n",
        "    lower_bound, upper_bound = bounds\n",
        "    df.loc[((df.family_onboard >= lower_bound) & (df.family_onboard <= upper_bound)), \"family_onboard_buckets\"] = value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Trhou0E8f3Pc"
      },
      "source": [
        "df.family_onboard_buckets.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8t1PQsduVob"
      },
      "source": [
        "#### is_parent_with_4_childrens Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UYiW4TVuV-T"
      },
      "source": [
        "df[\"is_parent_with_3_childrens_or_more\"] = np.where(df.Parch>2, 1, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asO-ORJ8vV2B"
      },
      "source": [
        "df[\"is_parent_with_3_childrens_or_more\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inBnoBUGxCUs"
      },
      "source": [
        "#### Drop unnecesary columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGV2mgi-XK8j"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO74Q0khw90G"
      },
      "source": [
        "df_column_list = ['Name', 'Cabin', 'Ticket', 'Sex', 'Age', 'Fare', 'fare_per_ticket', 'family_onboard', 'SibSp', 'Parch']\n",
        "df = df.drop(df_column_list, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIGuvlAQx2x0"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "st0ewZG1yo0P"
      },
      "source": [
        "### Split features & target variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocVAR1GQyoEE"
      },
      "source": [
        "X = df.drop([target_variable], axis=1)\n",
        "y = df[target_variable]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybVTQevaxaLS"
      },
      "source": [
        "### Handle Categorical Features & Scalling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6Z_Iw8uc7Bq"
      },
      "source": [
        "#### Split to categorical and non-categorical dfs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3oAjW0w14Iu"
      },
      "source": [
        "categorical_columns=['Embarked', 'Passanger Title', 'Cabin Class']\n",
        "X_categorical = X[categorical_columns]\n",
        "non_categorical_columns = [column for column in X.columns if column not in categorical_columns]\n",
        "X_non_categorical = X[non_categorical_columns]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9k9UABn7dFpC"
      },
      "source": [
        "#### OneHotEncoder Categorical Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlHJzk_gyVPr"
      },
      "source": [
        "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "encoder.fit(X_categorical)\n",
        "cat_features_names = list(encoder.get_feature_names(X_categorical.columns))\n",
        "\n",
        "X_categorical_transformed = encoder.transform(X_categorical)\n",
        "#X_categorical_transformed_dense = X_categorical_transformed.todense()\n",
        "\n",
        "X_categorical_transformed_df = pd.DataFrame(X_categorical_transformed, columns=cat_features_names, index=X_categorical.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUdB9F91w8ah"
      },
      "source": [
        "#### Scalling the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYkzqdkOxAYu"
      },
      "source": [
        "# data_scaler = MinMaxScaler()\n",
        "# X_train = pd.DataFrame(scaler.fit_transform(X_train), index=X_train.index, columns=X_train.columns)\n",
        "# X_test = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EL76PjMYjlQt"
      },
      "source": [
        "#### Join Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX8qBDBojldi"
      },
      "source": [
        "X = pd.merge(X_non_categorical, X_categorical_transformed_df, left_index=True, right_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGuWhLtwsTH3"
      },
      "source": [
        "# **Model train - Research**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GidWYE8lY56u"
      },
      "source": [
        "#### **Data balancing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Szon8x-TY-9n"
      },
      "source": [
        "class_weights_list = list(compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw3sR2cuweZv"
      },
      "source": [
        "#### **Split the Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8j3bgFpwmKm"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state =0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yH9ko6HskR3"
      },
      "source": [
        "### **Test approaches**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCaT-D_sxYjR"
      },
      "source": [
        "#### **Define evaluation metrics function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72_MJ0gXxZGh"
      },
      "source": [
        "def print_evaluation_metrics(model):\n",
        "    print(f\"for model {str(model.__class__).split('.')[-1][:-2]}:\")\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    print(\"Train set Metrics:\")\n",
        "    print(classification_report(y_train, y_train_pred))\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    print(\"Test set Metrics:\")\n",
        "    print(classification_report(y_test, y_test_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9jL64wKrvsE"
      },
      "source": [
        "#### **Decision Tree**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Fr1SDuWr4DU"
      },
      "source": [
        "desicion_tree_model = DecisionTreeClassifier(max_depth=4, class_weight='balanced')\n",
        "desicion_tree_model.fit(X_train, y_train)\n",
        "print_evaluation_metrics(desicion_tree_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t8oUU3PwY7s"
      },
      "source": [
        "#### **Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCW5CXyTwZ4D"
      },
      "source": [
        "logistic_regression_model = LogisticRegression(class_weight='balanced')\n",
        "logistic_regression_model.fit(X_train, y_train)\n",
        "print_evaluation_metrics(logistic_regression_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm2vLIUNzrvR"
      },
      "source": [
        "#### **KNN Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8R64IMc1zpe1"
      },
      "source": [
        "knn_classifier_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_classifier_model.fit(X_train, y_train)\n",
        "print_evaluation_metrics(knn_classifier_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddUi3pan0c4c"
      },
      "source": [
        "#### **SVM (SVC) Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6giJVorW0dV1"
      },
      "source": [
        "svc_classifier_model = SVC(class_weight='balanced')\n",
        "svc_classifier_model.fit(X_train, y_train)\n",
        "print_evaluation_metrics(svc_classifier_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7kBu3W61F26"
      },
      "source": [
        "#### **Random Forest Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eh0JZ9lr1GCh"
      },
      "source": [
        "random_forest_model = RandomForestClassifier(n_estimators=300, max_depth=4, class_weight=None)\n",
        "random_forest_model.fit(X_train, y_train)\n",
        "print_evaluation_metrics(random_forest_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APc9hBck4fG1"
      },
      "source": [
        "#### **Xgboost Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii-f7f5Y4flz"
      },
      "source": [
        "param_dist = {'objective':'binary:logistic', 'n_estimators':380, 'max_depth':3}\n",
        "\n",
        "clf = XGBClassifier(**param_dist)\n",
        "\n",
        "clf.fit(X_train, y_train,\n",
        "        eval_set=[(X_train, y_train), (X_test, y_test)],\n",
        "        eval_metric='logloss',\n",
        "        verbose=False)\n",
        "\n",
        "evals_result = clf.evals_result()\n",
        "print_evaluation_metrics(clf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsrHkhk_GU0t"
      },
      "source": [
        "# **Production - Train a model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eCHltDoxOl8"
      },
      "source": [
        "## **Pre-process**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgzP6aHJx0gr"
      },
      "source": [
        "### **Pre-process: Read data and split to train, test, evaluation data sets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tTbq-25HMj6"
      },
      "source": [
        "##### **Read Data file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZPli4bpHT-T"
      },
      "source": [
        "df_train = pd.read_csv(r'train.csv', encoding=\"UTF-8\", index_col=\"PassengerId\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft92xARjHets"
      },
      "source": [
        "##### **Target Varibale Definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLoKaXKBHgQE"
      },
      "source": [
        "target_variable = \"Survived\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7N5sutzyHrgb"
      },
      "source": [
        "##### **Split to target & features dfs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpeOqXosHr2r"
      },
      "source": [
        "X = df_train.drop(target_variable, axis=1)\n",
        "y = df_train[target_variable]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NdWAbh2ITA5"
      },
      "source": [
        "##### **Split to train, evaluation, test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQvX5hO2ITKL"
      },
      "source": [
        "X_train_temp, X_test, y_train_temp, y_test = train_test_split(X, y, test_size=0.1, random_state =0, stratify=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYLrMygiv83V"
      },
      "source": [
        "X_train, X_evaluation, y_train, y_evaluation = train_test_split(X_train_temp, y_train_temp, test_size=0.1, random_state =0, stratify=y_train_temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b21tYnP3AU-8"
      },
      "source": [
        "### **Feature Extraction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtdtEiAtxpyM"
      },
      "source": [
        "#### **Handle Nulls Transformers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARqHXJ9uxpyO"
      },
      "source": [
        "##### Handle Nulls and 0s in age (and create title feature)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua8v_t8Pz30i"
      },
      "source": [
        "title_dict = {  \n",
        "                \"Mr\" : \"Mr\",\n",
        "                \"Miss\" : \"Miss\",\n",
        "                \"Mrs\" : \"Mrs\",\n",
        "                \"Master\" : \"Master\",\n",
        "                \"Dr\" : \"Mr\",\n",
        "                \"Rev\" : \"Other\",\n",
        "                \"Col\" : \"Other\",\n",
        "                \"Major\" : \"Mr\",\n",
        "                \"Mlle\" : \"Miss\",\n",
        "                \"Jonkheer\" : \"Other\",\n",
        "                \"Lady\" : \"Mrs\",\n",
        "                \"Capt\" : \"Mr\",\n",
        "                \"Sir\" : \"Mr\",\n",
        "                \"Mme\" : \"Miss\",\n",
        "                \"Countess\" : \"Mrs\",\n",
        "                \"Ms\" : \"Miss\",\n",
        "                \"Don\" : \"Mr\"\n",
        "                }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8m8oGvQyyhMa"
      },
      "source": [
        "class TitleCreatorTransformer(TransformerMixin):\n",
        "    def __init__(self, title_dict):\n",
        "        self.regex_pattern = ('([a-zA-z]*)\\.(.*)')\n",
        "        self.name_column = 'Name'\n",
        "        self.title_dict = title_dict\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        X['Passanger Title'] = X[self.name_column].apply(self.extract_title_from_name)\n",
        "        X['Passanger Title'] = np.where(X['Passanger Title'].isin(title_dict), X['Passanger Title'].map(self.title_dict), \"Other\")\n",
        "        return X\n",
        "\n",
        "    def extract_title_from_name(self, string):\n",
        "        title = re.search(self.regex_pattern, string)\n",
        "        if not title:\n",
        "            return 'No Title'\n",
        "        return title.group(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wY7MR3Wd1oIJ"
      },
      "source": [
        "class FillAgeTransformer(TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.age_dict = {}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.age_dict = X.groupby(['Passanger Title'])['Age'].mean().to_dict()\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        X.loc[(X['Age'].isnull()) | (X['Age']==0),'Age'] = X['Passanger Title']\\\n",
        "        .map(self.age_dict)   \n",
        "        return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1hYJmNExpyp"
      },
      "source": [
        "##### Handle Nulls and 0s in Embarked"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YXrzCK65a-z"
      },
      "source": [
        "class FillNullsWithMaxIdTransformer(TransformerMixin):\n",
        "    def __init__(self, column):\n",
        "        self.column = column\n",
        "        self.max_id = ''\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.max_id = X[self.column].value_counts().idxmax()\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        X.loc[X[self.column].isnull(), self.column] = str(self.max_id)\n",
        "        return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Inwzy6Yhxpyw"
      },
      "source": [
        "##### Handle with 0's in Cabin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlziR3Vj7lu4"
      },
      "source": [
        "class ExtractCabinTransformer(TransformerMixin):\n",
        "    def __init__(self, input_column):\n",
        "        self.regex_pattern = ('^([A-Z])(\\d*)$')\n",
        "        self.input_column = input_column\n",
        "        self.output_column = f'{self.input_column} Feature'\n",
        "        \n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        X[self.output_column] = X[self.input_column].fillna('Not Mentioned') \\\n",
        "        .apply(self.extract_cabin_class_from_cabin)\n",
        "        return X\n",
        "\n",
        "    def extract_cabin_class_from_cabin(self, string):\n",
        "        cabin_class = re.search(self.regex_pattern, string)\n",
        "        if not cabin_class:\n",
        "            return 'Not Mentioned'\n",
        "        return cabin_class.group(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDLKXtmDCyMP"
      },
      "source": [
        "#### **Feature Extraction Transformers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXZoGO9_CyMR"
      },
      "source": [
        "##### Fare Per Ticket"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMdEMYPsCyMS"
      },
      "source": [
        "def calculate_fare_per_person(df, id = 'Ticket', groupyby_key = 'Ticket', fare='Fare'):\n",
        "    num_member_dict = df.groupby([groupyby_key])[id].count().to_dict()\n",
        "    df.loc[:,'num_of_members'] = df[groupyby_key].map(num_member_dict)\n",
        "    df['fare_per_ticket'] = df[fare] / df['num_of_members']\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMsIYv5jf6_H"
      },
      "source": [
        "##### Fare Per Ticket Buckets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K87MxeOsdRnj"
      },
      "source": [
        "class FareBucketsTransformer(TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.fare_buckets = []\n",
        "        \n",
        "    def fit(self, X, y=None):\n",
        "        self.fare_buckets = pd.qcut(X['fare_per_ticket'],4).unique().to_list()\n",
        "        self.fare_buckets = sorted(self.fare_buckets, key=lambda fare_bucket: fare_bucket.left)\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        for index, bounds in enumerate(self.fare_buckets):\n",
        "            lower_bound, upper_bound = bounds.left, bounds.right\n",
        "            if bounds == self.fare_buckets[-1]:\n",
        "                X.loc[X.fare_per_ticket>lower_bound, \"fare_buckets\"] = index\n",
        "            else:\n",
        "                X.loc[((X.fare_per_ticket > lower_bound) & (X.fare_per_ticket <= upper_bound)), \"fare_buckets\"] = index\n",
        "        #X.loc[X[\"fare_buckets\"].isnull(), \"fare_buckets\"] = -1\n",
        "        return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsYyoUZ3CyMk"
      },
      "source": [
        "##### Age Buckets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9mTzJZFBnX4"
      },
      "source": [
        "class AgeBucketsTransformer(TransformerMixin):\n",
        "    def __init__(self, age_buckets_dict):\n",
        "        self.age_buckets_dict = age_buckets_dict\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        for bounds, value in self.age_buckets_dict.items():\n",
        "            lower_bound, upper_bound = bounds\n",
        "            X.loc[((X.Age > lower_bound) & (X.Age <= upper_bound)), \"age_buckets\"] = value\n",
        "        X.loc[X.age_buckets.isnull(), \"age_buckets\"] = -1\n",
        "        return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7fUjRcpCyMm"
      },
      "source": [
        "age_buckets_dict = {\n",
        "                    (0, 18) : 0,\n",
        "                    (18, 29) : 1,\n",
        "                    (29, 40) : 2,\n",
        "                    (40, 55) : 3,\n",
        "                    (55,  math.inf): 4\n",
        "                    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtt9eyCFCyMq"
      },
      "source": [
        "##### Gender"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNxwtSswCyMr"
      },
      "source": [
        "class GenderBinarizerTransformer(TransformerMixin):\n",
        "    def __init__(self, column):\n",
        "        self.column = column\n",
        "        self.label_binarizer = LabelBinarizer()\n",
        "        \n",
        "    def fit(self, X, y=None):\n",
        "        self.label_binarizer.fit(X[self.column])\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        X['is_male?'] = self.label_binarizer.transform(X[self.column])\n",
        "        return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58zoG3DRCyMs"
      },
      "source": [
        "##### number of family members onboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Kqaf1CWCyMt"
      },
      "source": [
        "def sum_two_columns_df(df, output_col='family_onboard', column1='Parch', column2='SibSp'):\n",
        "    df.loc[:, output_col] = df[column1] + df[column2]\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ewQ4HbDCyMx"
      },
      "source": [
        "family_onboard_dict = {\n",
        "                    (0, 0) : 0,\n",
        "                    (1, 1) : 1,\n",
        "                    (2, 2) : 2,\n",
        "                    (3,  math.inf) : 3\n",
        "                    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9U_XndwnGTH"
      },
      "source": [
        "class FamilyMembersTransformer(TransformerMixin):\n",
        "    def __init__(self, family_onboard_dict):\n",
        "        self.family_onboard_dict = family_onboard_dict\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        for bounds, value in self.family_onboard_dict.items():\n",
        "            lower_bound, upper_bound = bounds\n",
        "            X.loc[((X.family_onboard >= lower_bound) & (X.family_onboard <= upper_bound)), \"family_onboard_buckets\"] = value\n",
        "        return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pns2jhV8CyM1"
      },
      "source": [
        "##### is_parent_with_4_childrens Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PJiQeFjCyM2"
      },
      "source": [
        "def is_parent_with_3_childrens_or_more(df):\n",
        "    df[\"is_parent_with_3_childrens_or_more\"] = np.where(df.Parch>2, 1, 0)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GASLWD9CyM4"
      },
      "source": [
        "##### Drop unnecesary columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lQes34SCyM8"
      },
      "source": [
        "def drop_columns(df):    \n",
        "    df_column_list = ['Name', 'Cabin', 'Ticket', 'Sex', 'Age', 'fare_buckets', 'fare_per_ticket', 'family_onboard', 'SibSp', 'Parch']#, 'Fare'\n",
        "    df = df.drop(df_column_list, axis=1)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptSz_z6Tqoi6"
      },
      "source": [
        "##### Handle Categorical Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GK3lC1Rqo7w"
      },
      "source": [
        "class CategoricalFeaturesTransformer(TransformerMixin):\n",
        "    def __init__(self, categorical_columns):\n",
        "        self.categorical_columns = categorical_columns\n",
        "        self.encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "        \n",
        "    def fit(self, X, y=None):\n",
        "        self.encoder.fit(X[self.categorical_columns])\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        X_categorical = X[self.categorical_columns]\n",
        "        non_categorical_columns = [column for column in X.columns if column not in self.categorical_columns]\n",
        "        X_non_categorical = X[non_categorical_columns]\n",
        "        cat_features_names = list(self.encoder.get_feature_names(X_categorical.columns))\n",
        "        X_categorical_transformed = self.encoder.transform(X_categorical)\n",
        "        X_categorical_transformed_df = pd.DataFrame(X_categorical_transformed, columns=cat_features_names, index=X_categorical.index)\n",
        "        X = pd.merge(X_non_categorical, X_categorical_transformed_df, left_index=True, right_index=True)\n",
        "        return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKodozMIsDkK"
      },
      "source": [
        "categorical_columns = ['Embarked', 'Passanger Title', 'Cabin Feature']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiAs6Kuzv2zc"
      },
      "source": [
        "## **Pipeline**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xlh2MYTv-UH"
      },
      "source": [
        "#### **Create data pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K8GDiMvv-4z"
      },
      "source": [
        "titanic_steps = [\n",
        "               ('title_creator', TitleCreatorTransformer(title_dict)),\n",
        "               ('fill_blanks_age', FillAgeTransformer()),\n",
        "               ('fill_blanks_embarked', FillNullsWithMaxIdTransformer('Embarked')),\n",
        "               ('extract_cabin', ExtractCabinTransformer('Cabin')),\n",
        "               ('fare_per_person', FunctionTransformer(calculate_fare_per_person)),\n",
        "               ('fare_buckets', FareBucketsTransformer()),\n",
        "               ('age_buckets', AgeBucketsTransformer(age_buckets_dict)),\n",
        "               ('gender_binarizer', GenderBinarizerTransformer('Sex')),\n",
        "               ('family_onboard', FunctionTransformer(sum_two_columns_df)),\n",
        "               ('family_onboard_buckets', FamilyMembersTransformer(family_onboard_dict)),\n",
        "               ('parent_w_3_or_more', FunctionTransformer(is_parent_with_3_childrens_or_more)),\n",
        "               ('drop_columns', FunctionTransformer(drop_columns)),\n",
        "               ('onehotencoder', CategoricalFeaturesTransformer(categorical_columns))#,\n",
        "               #('XGBoost_Classifier', XGBClassifier(**param_dist))\n",
        "               ]\n",
        "\n",
        "titanic_pipeline = Pipeline(steps=titanic_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMjjwHuXQngV"
      },
      "source": [
        "#### **Fit pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "248W6GdnQngb"
      },
      "source": [
        "X_train = titanic_pipeline.fit_transform(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "la7M7W5CQ1t1"
      },
      "source": [
        "#### **transform pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv-rm2wmQ1t3"
      },
      "source": [
        "X_evaluation = titanic_pipeline.transform(X_evaluation)\n",
        "X_test = titanic_pipeline.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNznbeurvxHO"
      },
      "source": [
        "#### **Modeling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL2zQlT3ILqh"
      },
      "source": [
        "##### **Xgboost Classifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-eOkZLIxFTe"
      },
      "source": [
        "###### **Xgboost Classifier - GridSearch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H219hey4XiNi"
      },
      "source": [
        "params = {\n",
        "        'min_child_weight': [1, 5, 10],\n",
        "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
        "        'subsample': [0.6, 0.8, 1.0],\n",
        "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "        'max_depth': [3], #, 4, 5],\n",
        "        'n_estimators': [200] #, 300, 400]\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gtv0-UYSILqn"
      },
      "source": [
        "xgb = XGBClassifier()\n",
        "\n",
        "skf = StratifiedKFold(n_splits=3, shuffle = True, random_state = 0)\n",
        "\n",
        "random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=200,\n",
        "                                   scoring='accuracy', n_jobs=4, \n",
        "                                   cv=skf.split(X_train,y_train), verbose=3, random_state=0)\n",
        "start_time = datetime.now()\n",
        "random_search.fit(X_train, y_train,\n",
        "        eval_set=[(X_train, y_train), (X_test, y_test)],\n",
        "        eval_metric='logloss',\n",
        "        verbose=False)\n",
        "print(f'\\n Time taken: {datetime.now()-start_time} seconds.')\n",
        "xgb_model = random_search.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmRpAMT9fGdE"
      },
      "source": [
        "random_search.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUV5kU-_xdt-"
      },
      "source": [
        "###### **Xgboost Classifier - fit**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FdhLgW5xXlt"
      },
      "source": [
        "param_dist = {'objective':'binary:logistic', 'colsample_bytree': 0.6,\n",
        " 'gamma': 1.5, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 200, \n",
        " 'subsample': 0.8}\n",
        "\n",
        "xgb_model = XGBClassifier(**param_dist)\n",
        "\n",
        "xgb_model.fit(X_train, y_train,\n",
        "        eval_set=[(X_train, y_train), (X_evaluation, y_evaluation)],\n",
        "        eval_metric='logloss',\n",
        "        verbose=False)\n",
        "\n",
        "evals_result = xgb_model.evals_result()\n",
        "print_evaluation_metrics(xgb_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc8360OfwAeD"
      },
      "source": [
        "## **Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6N6lSRcUV75H"
      },
      "source": [
        "#### **Predict**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8xekGDKV8W1"
      },
      "source": [
        "y_train_pred = xgb_model.predict(X_train)\n",
        "y_evaluation_pred = xgb_model.predict(X_evaluation)\n",
        "y_test_pred = xgb_model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIXBjMMDHyAf"
      },
      "source": [
        "#### **Define evaluation metrics function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U26_VvIxHyAj"
      },
      "source": [
        "def print_evaluation_metrics(y_actual, y_pred, dataset):\n",
        "    print(f\"{dataset} set Metrics:\")\n",
        "    print(classification_report(y_actual, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMQQNqQvTt4Y"
      },
      "source": [
        "#### **Get evaluation metrics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqH8ItatTuDv"
      },
      "source": [
        "datasets_dict = {'train': (y_train, y_train_pred), 'evaluation': (y_evaluation, y_evaluation_pred), 'test': (y_test, y_test_pred)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6225c9cFUTyW"
      },
      "source": [
        "for dataset, (y_actual, y_pred) in datasets_dict.items():\n",
        "    print_evaluation_metrics(y_actual, y_pred, dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jg8SywGTwH0S"
      },
      "source": [
        "## **Model Performance Visualization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUj0mxeQjqX5"
      },
      "source": [
        "#### **ROC Curve**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3Bhtfr0e94_"
      },
      "source": [
        "ns_probs = [0 for _ in range(len(y_train))]\n",
        "lr_probs = xgb_model.predict_proba(X_train)\n",
        "lr_probs = lr_probs[:, 1]\n",
        "ns_auc = roc_auc_score(y_train, ns_probs)\n",
        "lr_auc = roc_auc_score(y_train, lr_probs)\n",
        "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
        "print('Xgboost: ROC AUC=%.3f' % (lr_auc))\n",
        "ns_fpr, ns_tpr, _ = roc_curve(y_train, ns_probs)\n",
        "lr_fpr, lr_tpr, _ = roc_curve(y_train, lr_probs)\n",
        "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
        "plt.plot(lr_fpr, lr_tpr, marker='.', label='Xgboost')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yi6dcQa2wNX8"
      },
      "source": [
        "#### **Feature Importance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSNiobfswNm2"
      },
      "source": [
        "pd.Series(xgb_model.feature_importances_, index=X_train.columns.values).sort_values().plot.barh(figsize=(4, 10), rot=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAZbJRRkl2zO"
      },
      "source": [
        "## **Save Winning Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWeyBJuwl-Pa"
      },
      "source": [
        "pickle.dump(xgb_model, open(\"best_model.pickle\", \"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEZ0G-YCAA6I"
      },
      "source": [
        "# **Production - Apply prediction on new data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6-lU-MzmNBF"
      },
      "source": [
        "df_test = pd.read_csv(r'test.csv', encoding=\"UTF-8\", index_col=\"PassengerId\")\n",
        "df_test_transformed = titanic_pipeline.transform(df_test)\n",
        "model = pickle.load(open(\"best_model.pickle\", \"rb\"))\n",
        "df_test_transformed_scored = pd.DataFrame(model.predict(df_test_transformed), columns=[\"Survived?\"], index=df_test.index)\n",
        "df_test_final_scored = pd.merge(df_test, df_test_transformed_scored[\"Survived?\"], how='left', left_index=True, right_index=True)\n",
        "df_test_final_scored.to_csv(r'test_scored.csv', encoding=\"UTF-8\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}